{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock value prediction from Open, High, Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "d = 0.2\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Download data and normalize it\n",
    "Data since 1950 to today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalize=True):\n",
    "    start = datetime.datetime(1950, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    df.drop(['Volume', 'Close'], 1, inplace=True)\n",
    "    \n",
    "    if normalize:        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "        df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "        df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "        df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_stock_data(stock_name, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot out the Normalized Adjusted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stock(stock_name):\n",
    "    df = get_stock_data(stock_name, normalize=True)\n",
    "    print(df.head())\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low  Adj Close\n",
      "Date                                               \n",
      "1950-01-03  0.000004  0.000000  0.000004   0.000000\n",
      "1950-01-04  0.000081  0.000077  0.000081   0.000077\n",
      "1950-01-05  0.000114  0.000109  0.000114   0.000110\n",
      "1950-01-06  0.000134  0.000129  0.000134   0.000130\n",
      "1950-01-09  0.000178  0.000174  0.000175   0.000170\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc33cea1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(stock_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set last day Adjusted Close as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    \n",
    "    train = result[:int(row), :] # 90% date\n",
    "    \n",
    "    pRow = round(0.99 * train.shape[0])\n",
    "    pTrain =  result[:int(pRow), :]\n",
    "    left_X_train = pTrain[:, :-1] # all data until day m\n",
    "    left_y_train = pTrain[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "    right_X_test = train[int(pRow):, :-1]\n",
    "    right_y_test = train[int(pRow):, -1][:,-1] \n",
    "    \n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "    \n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1] \n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [left_X_train, left_y_train, right_X_test, right_y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15148, 22, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1], X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15148"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Buidling neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model2(shape, neurons, d)\n",
    "# layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13633 samples, validate on 1515 samples\n",
      "Epoch 1/300\n",
      "13633/13633 [==============================] - 19s - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "13633/13633 [==============================] - 17s - loss: 4.6008e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "13633/13633 [==============================] - 15s - loss: 2.1895e-04 - acc: 0.0000e+00 - val_loss: 5.6247e-04 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "13633/13633 [==============================] - 15s - loss: 1.5218e-04 - acc: 0.0000e+00 - val_loss: 3.3848e-04 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "13633/13633 [==============================] - 15s - loss: 1.2970e-04 - acc: 0.0000e+00 - val_loss: 2.9603e-04 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "10752/13633 [======================>.......] - ETA: 3s - loss: 1.2464e-04 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot out prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value):\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "    \n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    plt2.plot(newp, color='red', label='Prediction')\n",
    "    plt2.plot(newy_test,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Adjusted Close')\n",
    "    plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('LSTM_Stock_prediction-20170429.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Fine tune model\n",
    "# 11. Function to load data, train model and see score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model2(shape, neurons, d)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Fine tune hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.1 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "dropout_result = {}\n",
    "\n",
    "for d in dlist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    dropout_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min(dropout_result.values())\n",
    "min_val_key = [k for k, v in dropout_result.items() if v == min_val]\n",
    "print (dropout_result)\n",
    "print (min_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(dropout_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.2 Optimial epochs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochslist = [10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_result = {}\n",
    "\n",
    "for epochs in epochslist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "    epochs_result[epochs] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(epochs_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.3 Optimal number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "epochs = 90\n",
    "dropout = 0.3\n",
    "neuronlist1 = [32, 64, 128, 256, 512]\n",
    "neuronlist2 = [16, 32, 64]\n",
    "neurons_result = {}\n",
    "\n",
    "for neuron_lstm in neuronlist1:\n",
    "    neurons = [neuron_lstm, neuron_lstm]\n",
    "    for activation in neuronlist2:\n",
    "        neurons.append(activation)\n",
    "        neurons.append(1)\n",
    "        trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs)\n",
    "        neurons_result[str(neurons)] = testScore\n",
    "        neurons = neurons[:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(neurons_result.items())\n",
    "x,y = zip(*lists)\n",
    "\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('Mean Square Error')\n",
    "\n",
    "plt.bar(range(len(lists)), y, align='center')\n",
    "plt.xticks(range(len(lists)), x)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "12.4 Optimial Dropout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "decaylist = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model3(layers, neurons, d, decay):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model3(shape, neurons, d, decay)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_result = {}\n",
    "\n",
    "for decay in decaylist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    decay_result[decay] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(decay_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Decay')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "neurons = [256, 256, 32, 1]\n",
    "epochs = 90\n",
    "d = 0.3 #dropout\n",
    "decay = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_list = [5, 10, 22, 60, 120, 180]\n",
    "\n",
    "seq_len_result = {}\n",
    "\n",
    "for seq_len in seq_len_list:\n",
    "    shape = [4, seq_len, 1]\n",
    "    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    seq_len_result[seq_len] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(seq_len_result.items())\n",
    "x,y = zip(*lists)\n",
    "plt.plot(x,y)\n",
    "plt.title('Finding the best hyperparameter')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
